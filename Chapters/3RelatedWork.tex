%*****************************************
\chapter{Stand der Forschung}\label{ch:relatedWork}
%*****************************************

In diesem Kapitel wird die verwendete Software beschrieben und die Vorarbeit, auf die sich diese Arbeit stützt erläutert.

\section{Whisper}
Whisper ist ein Open-Source-Transkriptionsmodell von OpenAI, welches mit 680.000 Stunden an Audio aus dem Internet in verschiedenen Sprachen trainiert wurde.
Aufgrund der weitreichenden Diversität der Trainingsdaten erreicht Whisper auch bei Akzenten und Fachsprache  hohe Genauigkeit \citep{whisper}.
Durch den großen Umfang des Trainings erreicht Whisper eine gute Zero-Shot-Performance, kommt also gut mit Daten zurecht, auf die es nicht spezifisch trainiert wurde.

%Vergleich vieler ASR Modelle anhand deutsch- und englischsprachiger Youtubevideo Ausschnitte: OpenAI Whisper in allen Kategorien niedrigste \ac{wer}, vor allem in deutscher Sprache mit 5.0 bei einem Durchschnitt von 15.3 (Platz 2: Speechmatics 8.0, Platz 3: Microsoft 10.1), allerdings am langsamsten \citet{VergleichASR2023}

\subsection{Whisper-Modelle}
Es existieren verschiedene Whisper-Modelle (\cref{tab:whisper_modelle})
Das größte dieser Modelle, Whisper large, gibt es in drei Versionen:
Whisper large, Whisper large-v2, Whisper large-v3.
Whisper turbo ist eine quantisierte Version von Whisper large-v3.
Die Modelle werden mit zunehmender Größe langsamer, aber auch genauer, das heißt die \ac{wer} nimmt ab.
Whisper Turbo ist dabei eine Ausnahme, weil es ähnlich genau wie Whisper large-v2 und gleichzeitig fast so schnell wie Whisper tiny ist \citep{distilwhisper}.

\begin{table}
\begin{tabulary}{\textwidth}{lS}
\toprule
\textbf{Modell} & \textbf{Parameter}\\
Tiny & \qty{39}{\mega\nounit}\\
Base & \qty{74}{\mega\nounit}\\
Small & \qty{244}{\mega\nounit}\\
Medium & \qty{769}{\mega\nounit}\\
Large & \qty{1550}{\mega\nounit}\\
Turbo & \qty{809}{\mega\nounit}\\
\bottomrule
\end{tabulary}
\caption{Whisper-Modelle}
\label{tab:whisper_modelle}
\end{table}

\section{noScribe}
Die Software noScribe~\citep{noscribe} ist eine Open Source Anwendung zum Transkribieren von Audioaufnahmen, welche eine Benutzeroberfläche inklusive Editor bereitstellt.
Sie verwendet standardmäßig OpenAI Whisper, ermöglicht aber auch das Hinzufügen anderer Modelle. 
Die Software noScribe läuft vollständig lokal, verwendet also kein externen Server für die Berechnung.
Das ist notwendig, da externe Anbieter in der Regel nicht die benötigte Leistung bereitstellen, welche hier aufgrund der Größe der Audiodateien sehr hoch ist.
Als Ergebnis der Transkription erhält man eine HTML Datei, welche während dem Vorgang regelmäßig automatisch gespeichert wird.
Das ist hilfreich, falls das Programm zwischendurch abstürzt oder auf anderem Weg unterbrochen wird.
Deben der Standartversion von noScribe gibt es eine weitere Variante, welche Nvidia CUDA verwendet, um die Prozesse über die Grafikkarte auszuführen und damit stark zu beschleunigen.
Dafür wird eine Nvidia Grafikkarte mit mindestens 6GB VRAM benötigt.

\section{Nvidia CUDA}
